
\section{Introduction}
\label{s-introductoin}

Jupyter notebooks~\citep{Kluyver2016} are increasingly used for scientific work.
Services like Binder~\citep{Jupyter2018}, colab \citep{Google2020, Carneiro2018}, or the Pangeo hubs\citep{robinson2019science}, that are based on public cloud infrastructure, are setting high standards for user experience (ELABORATE ON UX ON BINDER, COLAB, PANGEO?).
There are numerous efforts to establish Jupyter based workflows in HPC centres or on-premise cloud infrastructure:
\begin{itemize}
  \item NCAR runs it on CHEYNENNE\footnote{https://www2.cisl.ucar.edu/resources/computational-systems/cheyenne/software/jupyter-and-ipython},
  \item DKRZ offers a JupyterHub\footnote{https://www.dkrz.de/up/systems/mistral/programming/jupyter-notebook},
  \item and JSC has a solution~\citep{Goebbert2018}.
\end{itemize}

From a user perspective, notebooks may be attractive because they allow for combining a narrative with technical details, code, data and figures and hence provide an integrated way of presenting a line of scientific reasoning, and because they can be created in an incremental and interactive process that in some cases is close the the thought process during scientific work.

Jupyter may be attractive for users because though originating from the Python ecosystem, it provides a common interface for creating notebooks that can contain code in many different languages.
Work with remote Jupyter instances, e.g., through a JupyterHub is popular, because the browser-based graphical application is executed on the user's computer and the bandwidth and stability requirements for the connection to the server are minimal and result in a low-latency and smooth user experience that is rare among classical GUIs that allow for execution on remote servers.

Besides Jupyter, there are other popular implementations of computational notebooks~\citep{Hinsen2019a} that increasingly provide a browser-based way of working with them\footnote{See, e.g., the Matlab Live Editor at https://de.mathworks.com/products/matlab/live-editor.html.}.

In this paper, we evaluate the JSC JupyterHub with respect to {\em Documentation}, {\em Accessibility}, {\em Flexibility}, {\em Availability}, and {\em Stability}.
Throughout the evaluation, the question if the service does or does not lead to an increase in productivity for scientists will be the guiding criterion.


\subsection{User requirements}

Jupyter on HPC is a solution for different user groups that profit for different reasons.
There is expert users who have substantial resource demands (computational power or storage which can only be provided by HPC) and who don't want to miss the familiar comfort of the integrated working environment (notebooks and visualization but also terminal access) provided by Jupyter.
But Juptyer can also bring non-expert users to HPC who lack the technical background to fully build their own commandline-based workflows, but who \emph{can} do meaningful science with the data and group or community specific toolboxes already available there.
While for expert users, it's easy to work with Jupyter on HPC without relying on a central service\footnote{see, e.g, https://git.geomar.de/python/jupyter_on_HPC_setup_guide}, for non-experts a JupyterHub service may be essential for opening up the HPC system at all.

Users will expect different levels of customizability, all of which are essential to at least some of the users.
Some users will want immediately usable default software environments and default resource choices that don't require intimate knowledge of HPC specifics.
Others will need full customizability not only f to the underlying Jupyter kernel and frontend software environment, but also of the spawning location.
These users might want access to all resources and to every specific part (e.g., GPU or large-memory nodes) of the HPC system that they could use with classical command-line access.

For all user groups, the provided documentation needs to be up-to-date with the JSC specific default state of the JupyterLab user interface.
The documentation should also be in sync with community documentation and best practices, because users are unlikely to be only exposed to Juptyer on one single datacentre.

Providing interactive access to HPC resources brings high demands in terms of availability of resources and of stability, which are more difficult to fulfil the more specific the needs of the users are.
Providing a way to fore-see availability of resources and hence plannable interactive sessions may help.

The resource requirements range from very low memory and CPU demands that could easily be fulfilled on a shared machine to requiring multiple HPC nodes or special hardware like GPUs.
So an pre-selected typical resource selection for non-expert users combined with the possibility of full selection of resources like memory and CPU, type and number of compute nodes, and duration of the session for expert users is a requirement.

To also allow for using Jupyter as a front end for managing other batch-type jobs, full access to the batch scheduler would be desirable.

Ready-to-use standard configurations can be oriented along popular software distributions like Anaconda or the Pyviz ecosystem. 
Full configurability of the Jupyter kernel would best follow community standards of managing working environments and could range from HPC-native module-based environment management, to Python virtual envs or conda envs (that are not restricted to Python), and to container based compute kernels.
Customization of the Jupyter frontend could be done by allowing user-installed Jupyter setups (again based on modules and other community standards of managing workflows).

Another possibility for full customizability that has considerable overlap with the way the data science community works on other platforms\footnote{Pangeo (https://pangeo.io) and the Binder project (https://mybinder.org) use containers on their cloud deployments that are built in a way that allows for re-use of the same container with Docker and Singulartiy on almost every platform.} would be to allow for containers that not only provide a compute kernel, but that bring a Jupyter setup that is adapted to one or more Jupyter kernels in a very detailed way.
This would treat the whole Jupyter user server including frontend and backend as one integrated application.

Persistent Jupyter sessions that can be reconnected at any point (within the allocated time window) help accomodating tasks with longer wait times, and allow for recovery after connectivity problems.

\subsection{Key service challenges}

(For web-based access to HPC resources.)

\begin{itemize}
  \item What are the technical obstacles to overcome from a user perspective? And from an HPC operator perspective?
  \item ...
\end{itemize}

\subsection{Cautionary note}

(We should mention that what we discuss here is formulated entirely from a user perspective and that we do not have detailed administrator insight into service configurations. Should probably be moved away from the introduction.) (We should also briefly explain why we take the "subjective" JupyterHub@JSC perspective.)
(We should also say that our "research objects" gradually changed during the evaluation period, and that some information provided here will and might have become obsolete.)
