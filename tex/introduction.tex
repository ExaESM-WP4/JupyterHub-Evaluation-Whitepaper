
\section{Introduction}
\label{s-introductoin}

Jupyter notebooks~\citep{Kluyver2016} are increasingly used for scientific work.
Services like Binder~\citep{Jupyter2018}, colab \citep{Google2020, Carneiro2018}, or the Pangeo hubs\citep{robinson2019science}, that are based on public cloud infrastructure, are setting high standards for user experience (ELABORATE ON UX ON BINDER, COLAB, PANGEO?).
There are numerous efforts to establish Jupyter based workflows in HPC centres or on-premise cloud infrastructure:
\begin{itemize}
  \item NCAR runs it on CHEYNENNE\footnote{https://www2.cisl.ucar.edu/resources/computational-systems/cheyenne/software/jupyter-and-ipython},
  \item DKRZ offers a JupyterHub\footnote{https://www.dkrz.de/up/systems/mistral/programming/jupyter-notebook},
  \item and JSC has a solution~\citep{Goebbert2018}.
\end{itemize}

From a user perspective, notebooks may be attractive because they allow for combining a narrative with technical details, code, data and figures and hence provide an integrated way of presenting a line of scientific reasoning, and because they can be created in an incremental and interactive process that in some cases is close the the thought process during scientific work.

Jupyter may be attractive for users because though originating from the Python ecosystem, it provides a common interface for creating notebooks that can contain code in many different languages.
Work with remote Jupyter instances, e.g., through a JupyterHub is popular, because the browser-based graphical application is executed on the user's computer and the bandwidth and stability requirements for the connection to the server are minimal and result in a low-latency and smooth user experience that is rare among classical GUIs that allow for execution on remote servers.

Besides Jupyter, there are other popular implementations of computational notebooks~\citep{Hinsen2019a} that increasingly provide a browser-based way of working with them\footnote{See, e.g., the Matlab Live Editor at https://de.mathworks.com/products/matlab/live-editor.html.}.


\subsection{User requirements}

Jupyter on HPC is a solution for different user groups that profit for different reasons.
There is expert users who have substantial resource demands (computational power or storage which can only be provided by HPC) and who don't want to miss the familiar comfort of the integrated working environment (notebooks and visualization but also terminal access) provided by Jupyter.
But Juptyer can also bring non-expert users to HPC who lack the technical background to fully build their own commandline-based workflows, but who \emph{can} do meaningful science with the data and group or community specific toolboxes already available there.
While for expert users, it's easy to work with Jupyter on HPC without relying on a central service\footnote{see, e.g, https://git.geomar.de/python/jupyter_on_HPC_setup_guide}, for non-experts a JupyterHub service may be essential for opening up the HPC system at all.

Users will expect different levels of customizability, all of which are essential to at least some of the users.
Some users will want immediately usable default software environments and default resource choices that don't require intimate knowledge of HPC specifics.
Others will need full customizability not only f to the underlying Jupyter kernel and frontend software environment, but also of the spawning location.
These users might want access to all resources and to every specific part (e.g., GPU or large-memory nodes) of the HPC system that they could use with classical command-line access.

For all user groups, the provided documentation needs to be up-to-date with the JSC specific default state of the JupyterLab user interface.
The documentation should also be in sync with community documentation and best practices, because users are unlikely to be only exposed to Juptyer on one single datacentre.

Providing interactive access to HPC resources brings high demands in terms of availability of resources and of stability, which are more difficult to fulfil the more specific the needs of the users are.
Providing a way to fore-see availability of resources and hence plannable interactive sessions may help.

The resource requirements range from very low memory and CPU demands that could easily be fulfilled on a shared machine to requiring multiple HPC nodes or special hardware like GPUs.
So an pre-selected typical resource selection for non-expert users combined with the possibility of full selection of resources like memory and CPU, type and number of compute nodes, and duration of the session for expert users is a requirement.

To also allow for using Jupyter as a front end for managing other batch-type jobs, full access to the batch scheduler would be desirable.

Ready-to-use standard configurations can be oriented along popular software distributions like Anaconda or the Pyviz ecosystem. 
Full configurability of the Jupyter kernel would best follow community standards of managing working environments and could range from HPC-native module-based environment management, to Python virtual envs or conda envs (that are not restricted to Python), and to container based compute kernels.
Customization of the Jupyter frontend could be done by allowing user-installed Jupyter setups (again based on modules and other community standards of managing workflows).

Another possibility for full customizability that has considerable overlap with the way the data science community works on other platforms\footnote{Pangeo (https://pangeo.io) and the Binder project (https://mybinder.org) use containers on their cloud deployments that are built in a way that allows for re-use of the same container with Docker and Singulartiy on almost every platform.} would be to allow for containers that not only provide a compute kernel, but that bring a Jupyter setup that is adapted to one or more Jupyter kernels in a very detailed way.
This would treat the whole Jupyter user server including frontend and backend as one integrated application.

Persistent Jupyter sessions that can be reconnected at any point (within the allocated time window) help accomodating tasks with longer wait times, and allow for recovery after connectivity problems.


\subsection{Key service challenges}

With a special focus on the user requirements stated above, the deployment challenges for a JupyterHub service on HPC are briefly discussed here.
Deployment details do not only have a strong impact upon system operator workload in maintaining a provided Jupyter service, but also decide about enabling and/or disabling user productivity, and with that whether the service adds value to the provided HPC system (software) infrastructure.

Challenges for system providers can be divided into three categories: HPC resources, working environments, and documentation.

Jupyter workflows are interactive by nature and hence, for the HPC resource management for Jupyter, sysadmins are mainly faced with the task of providing a decent amount of HPC resources quickly.

While system administrators know a lot about their HPC system and are unquestionably experts in choosing and optimizing low-level libraries for their hardware, higher up in the software stack the expertise shifts to the actual users of the software.
Thus, finding the right cut between low-level libraries taken care of by sysadmins and high-level libraries managed by scientific users is difficult.

The same divide is present on the documentation level.
On one hand, the complexity of HPC system infrastructure (with their already highly specialized compute/storage implementations, which are currently e.g. supplemented by co-processing and/or general purpose processing GPUs) requires documentation and user training to ensure efficient usage of the specialised hardware modules and to help users in optimizing their software for the underlying hardware.
On the other hand, it cannot be expected that system providers are the best for writing documentation on high-level data-analysis software and workflows.

While the processing capability of such systems increases, inefficient usage of the increasingly complex hardware infrastructure especially by untrained users poses a strong risk on their cost effective sustenance\cite{}.
This risk might further increase by also increasing the complexity of the provided software infrastructure.


\subsection{Jupyter service levels}

From a user perspective (and only in a very principle way) the Jupyter services provided by high-performance computing centers might be categorized as follows

\begin{itemize}
  \item (dummy text)
\end{itemize}

\subsection{Scope of this paper}

In this paper, we take the user perspective and evaluate the JSC JupyterHub with respect to {\em Documentation}, {\em Accessibility}, {\em Flexibility}, {\em Availability}, and {\em Stability}.
In doing so, we rely on information that is available to any standard user of the system only.
Throughout the evaluation, the question if the service does or does not lead to an increase in productivity for scientists will be the key guiding criterion.

The Jupyter@JSC is under heavy development and is a moving target for the evaluation presented here.
Hence, some of the detailed information provided here might have and will become obsolete.

Jupyter@JSC is a good candidate for the comprehensive evaluation of Jupyter on HPC systems, because it is aimed at providing a full-scale access to the underlying HPC system and hence is likely to hit on many of the challenges that arise for the deployment of such a service. 
